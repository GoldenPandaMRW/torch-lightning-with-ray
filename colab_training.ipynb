{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Armor U-Net Training on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook installs the project dependencies, syncs the repository, configures paths/hyperparameters, and runs `train_armor_detector` using the same codebase as the main repo. Adjust the form fields as needed for your dataset location or run length before executing the training cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_check"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability (optional but recommended)\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install the Python dependencies needed by the project\n",
        "!pip install --quiet pytorch-lightning>=2.2 albumentations>=1.3 wandb>=0.16 pillow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Mount Google Drive\n",
        "USE_DRIVE = False  # @param {type:\"boolean\"}\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "#@title Clone or update the repository\n",
        "import os, subprocess, sys, pathlib\n",
        "REPO_URL = \"https://github.com/YOUR_USERNAME/torch-lightning-with-ray.git\"  # @param {type:\"string\"}\n",
        "TARGET_DIR = \"/content/torch-lightning-with-ray\"  # @param {type:\"string\"}\n",
        "target_path = pathlib.Path(TARGET_DIR)\n",
        "if not target_path.exists():\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, str(target_path)], check=True)\n",
        "else:\n",
        "    subprocess.run([\"git\", \"-C\", str(target_path), \"pull\"], check=True)\n",
        "os.chdir(target_path)\n",
        "if str(target_path) not in sys.path:\n",
        "    sys.path.insert(0, str(target_path))\n",
        "print(f'Working directory: {target_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "configure_paths"
      },
      "outputs": [],
      "source": [
        "#@title Configure data/log locations and key hyperparameters\n",
        "import os, pathlib\n",
        "DATA_ROOT = \"/content/Dataset_Robomaster-1\"  # @param {type:\"string\"}\n",
        "CHECKPOINT_DIR = \"/content/checkpoints\"  # @param {type:\"string\"}\n",
        "LOG_DIR = \"/content/logs\"  # @param {type:\"string\"}\n",
        "BATCH_SIZE = 4  # @param {type:\"integer\"}\n",
        "MAX_EPOCHS = 5  # @param {type:\"integer\"}\n",
        "BASE_CHANNELS = 32  # @param {type:\"integer\"}\n",
        "LEARNING_RATE = 1e-4  # @param {type:\"number\"}\n",
        "for path in (DATA_ROOT, CHECKPOINT_DIR, LOG_DIR):\n",
        "    pathlib.Path(path).mkdir(parents=True, exist_ok=True)\n",
        "os.environ['DATA_ROOT'] = DATA_ROOT\n",
        "os.environ['CHECKPOINT_DIR'] = CHECKPOINT_DIR\n",
        "os.environ['LOG_DIR'] = LOG_DIR\n",
        "print(f'DATA_ROOT: {DATA_ROOT}')\n",
        "print(f'CHECKPOINT_DIR: {CHECKPOINT_DIR}')\n",
        "print(f'LOG_DIR: {LOG_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wandb_login"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate with Weights & Biases\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_training"
      },
      "outputs": [],
      "source": [
        "#@title Run training\n",
        "from train import train_armor_detector\n",
        "model, trainer, datamodule = train_armor_detector(\n",
        "    data_root=DATA_ROOT,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    max_epochs=MAX_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    base_channels=BASE_CHANNELS,\n",
        "    checkpoint_dir=CHECKPOINT_DIR,\n",
        "    log_dir=LOG_DIR,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
